{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,f1_score, precision_score, recall_score, accuracy_score\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/modified_0420.csv\")\n",
    "x_train = df.drop(columns=['loan_status', 'Unnamed: 0'])\n",
    "y_train = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(y_train, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['all_util', 'annual_inc', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'delinq_amnt', 'dti', 'fico_range_low', 'home_ownership', 'max_bal_bc', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mort_acc', 'mths_since_recent_bc', 'num_accts_ever_120_pd', 'open_acc', 'open_act_il', 'purpose', 'revol_bal', 'tax_liens', 'tot_cur_bal', 'tot_hi_cred_lim', 'total_acc', 'total_bal_ex_mort', 'total_bal_il', 'total_bc_limit', 'total_cu_tl', 'total_il_high_credit_limit', 'total_rev_hi_lim', 'verification_status'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/modified_0420_reversed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_util\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannual_inc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_cur_bal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbc_open_to_buy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbc_util\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchargeoff_within_12_mths\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelinq_amnt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdti\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memp_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfico_range_low\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhome_ownership\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloan_amnt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloan_status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_bal_bc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmo_sin_old_il_acct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmo_sin_old_rev_tl_op\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmort_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmths_since_recent_bc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_accts_ever_120_pd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen_act_il\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpurpose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrevol_bal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrevol_util\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_grade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtax_liens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mterm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtot_cur_bal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtot_hi_cred_lim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_bal_ex_mort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_bal_il\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_bc_limit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_cu_tl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_il_high_credit_limit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_rev_hi_lim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverification_status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstallment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m y_train \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_status\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['all_util', 'annual_inc', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'delinq_amnt', 'dti', 'fico_range_low', 'home_ownership', 'max_bal_bc', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mort_acc', 'mths_since_recent_bc', 'num_accts_ever_120_pd', 'open_acc', 'open_act_il', 'purpose', 'revol_bal', 'tax_liens', 'tot_cur_bal', 'tot_hi_cred_lim', 'total_acc', 'total_bal_ex_mort', 'total_bal_il', 'total_bc_limit', 'total_cu_tl', 'total_il_high_credit_limit', 'total_rev_hi_lim', 'verification_status'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/modified_0420_reversed.csv\")\n",
    "x_train = df[['all_util','annual_inc','application_type','avg_cur_bal',\n",
    "              'bc_open_to_buy','bc_util','chargeoff_within_12_mths',\n",
    "              'delinq_amnt','dti','emp_length','fico_range_low',\n",
    "              'home_ownership','loan_amnt','loan_status','max_bal_bc','mo_sin_old_il_acct','mo_sin_old_rev_tl_op',\n",
    "              'mort_acc','mths_since_recent_bc','num_accts_ever_120_pd','open_acc','open_act_il','purpose','revol_bal',\n",
    "              'revol_util','sub_grade','tax_liens','term','tot_cur_bal','tot_hi_cred_lim','total_acc','total_bal_ex_mort','total_bal_il',\n",
    "              'total_bc_limit','total_cu_tl','total_il_high_credit_limit','total_rev_hi_lim','verification_status','int_rate','installment']]\n",
    "y_train = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = np.isnan(x_train).any(axis=1)\n",
    "x_train = x_train[~nan_indices]\n",
    "y_train = y_train[~nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaler 찾아보기\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18327392 0.30497601 0.39814743 0.48561711 0.56080978 0.62500875\n",
      " 0.67280327 0.71057396 0.7426013  0.77122589 0.79708099 0.81842172\n",
      " 0.83694587 0.85416773 0.8690716  0.88254502 0.89533955 0.90412335\n",
      " 0.91149629 0.91878454 0.9256441  0.93060517 0.93522633 0.93943754\n",
      " 0.94348896 0.94734647 0.95093045 0.95404078 0.9570436  0.95992968\n",
      " 0.96266619 0.96534988 0.96788059 0.97015371 0.97227543 0.97428156\n",
      " 0.97620044 0.97800839 0.97976168 0.98150946 0.98306543 0.98460667\n",
      " 0.98588465 0.98714241 0.98821465 0.98924093 0.99015911 0.99099451\n",
      " 0.99181852 0.99258112 0.99331473 0.99400211 0.99461361 0.99514955\n",
      " 0.99563382 0.99604969 0.99644021 0.99677312 0.99708772 0.99735254\n",
      " 0.99761602 0.9978731  0.9981232  0.99835468 0.99857926 0.99877683\n",
      " 0.99896599 0.99915263 0.99928699 0.99940035 0.99949712 0.99958652\n",
      " 0.99966456 0.99973456 0.99979385 0.99983478 0.99986882 0.99990138\n",
      " 0.99993103 0.99995843 0.99997325 0.99998633 0.9999917  0.99999631\n",
      " 0.99999888 1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_components_from_pca(scaled_data:pd.DataFrame, threshold:float) -> int:\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_data)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "    print(cumulative_explained_variance)\n",
    "    # 누적 설명 분산 시각화\n",
    "    plt.plot(cumulative_explained_variance, marker='o', linestyle='-')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('Cumulative Explained Variance by Number of Components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # 적절한 주성분 개수 선택\n",
    "    n_components = np.argmax(cumulative_explained_variance >= threshold) + 1\n",
    "    return n_components\n",
    "get_n_components_from_pca(X_scaled, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA로 차원 축소\n",
    "pca = PCA(n_components=27)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "x_train = X_pca.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "x_train, y_train = tl.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=30)\n",
    "x_train, y_train = ros.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify로 학습에 용이하게 비율 유지\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 아래 칸은 최적의 hyperparameter를 찾기 위해서 실행하는 칸이므로, 실행할 필요 없습니다.\n",
    "\n",
    "모델만을 알고싶다면 넘어가세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4872 - accuracy: 0.7915\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7985\n",
      "182/182 [==============================] - 0s 829us/step - loss: 0.4592 - accuracy: 0.7992\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4908 - accuracy: 0.7951\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 868us/step - loss: 0.4597 - accuracy: 0.7978\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.7972\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 873us/step - loss: 0.4600 - accuracy: 0.7979\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4875 - accuracy: 0.7902\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 835us/step - loss: 0.4575 - accuracy: 0.8002\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4853 - accuracy: 0.7945\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 831us/step - loss: 0.4583 - accuracy: 0.7996\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4796 - accuracy: 0.7960\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 910us/step - loss: 0.4587 - accuracy: 0.8000\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.7948\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 841us/step - loss: 0.4593 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7935\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 833us/step - loss: 0.4596 - accuracy: 0.7986\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.7968\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 849us/step - loss: 0.4573 - accuracy: 0.8005\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7978\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 829us/step - loss: 0.4582 - accuracy: 0.8000\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.7912\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 899us/step - loss: 0.4581 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4764 - accuracy: 0.7976\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 879us/step - loss: 0.4584 - accuracy: 0.7989\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4762 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 893us/step - loss: 0.4592 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.7916\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 873us/step - loss: 0.4569 - accuracy: 0.8010\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4748 - accuracy: 0.7978\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 945us/step - loss: 0.4580 - accuracy: 0.8003\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7895\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4693 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7984\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4893 - accuracy: 0.7917\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4671 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4953 - accuracy: 0.7930\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4699 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4893 - accuracy: 0.7937\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4695 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 965us/step - loss: 0.4590 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4936 - accuracy: 0.7883\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4667 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 941us/step - loss: 0.4600 - accuracy: 0.7989\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4800 - accuracy: 0.7970\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7986\n",
      "182/182 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4904 - accuracy: 0.7885\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 976us/step - loss: 0.4603 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.7910\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 974us/step - loss: 0.4614 - accuracy: 0.7982\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4839 - accuracy: 0.7947\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 956us/step - loss: 0.4589 - accuracy: 0.7997\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4792 - accuracy: 0.7966\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 960us/step - loss: 0.4589 - accuracy: 0.7987\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4762 - accuracy: 0.7976\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 983us/step - loss: 0.4591 - accuracy: 0.7989\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4802 - accuracy: 0.7946\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4643 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 930us/step - loss: 0.4593 - accuracy: 0.7974\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4784 - accuracy: 0.7975\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 948us/step - loss: 0.4607 - accuracy: 0.7980\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.7900\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4655 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 968us/step - loss: 0.4575 - accuracy: 0.8007\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4783 - accuracy: 0.7968\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4640 - accuracy: 0.7985\n",
      "182/182 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4893 - accuracy: 0.7973\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4698 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4938 - accuracy: 0.7921\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4686 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7972\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4948 - accuracy: 0.7950\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4979 - accuracy: 0.7910\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4706 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4933 - accuracy: 0.7957\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4693 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4836 - accuracy: 0.7969\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4881 - accuracy: 0.7933\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4665 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7975\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4852 - accuracy: 0.7962\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4674 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4829 - accuracy: 0.7974\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4672 - accuracy: 0.7977\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4913 - accuracy: 0.7922\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4684 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4876 - accuracy: 0.7928\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4656 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7985\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4838 - accuracy: 0.7958\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4647 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7973\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4851 - accuracy: 0.7949\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4662 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7972\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4789 - accuracy: 0.7963\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4654 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4821 - accuracy: 0.7972\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4654 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.7948\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 993us/step - loss: 0.4589 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4909 - accuracy: 0.7911\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7976\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4991 - accuracy: 0.7802\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 929us/step - loss: 0.4603 - accuracy: 0.7982\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.7923\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 878us/step - loss: 0.4577 - accuracy: 0.7997\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4910 - accuracy: 0.7916\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 879us/step - loss: 0.4587 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4815 - accuracy: 0.7953\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 885us/step - loss: 0.4586 - accuracy: 0.7994\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4794 - accuracy: 0.7975\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 864us/step - loss: 0.4587 - accuracy: 0.7984\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4808 - accuracy: 0.7943\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 874us/step - loss: 0.4597 - accuracy: 0.7986\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4864 - accuracy: 0.7930\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 860us/step - loss: 0.4570 - accuracy: 0.8013\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4827 - accuracy: 0.7938\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 923us/step - loss: 0.4582 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4795 - accuracy: 0.7947\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4629 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8000\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4790 - accuracy: 0.7957\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4628 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4807 - accuracy: 0.7929\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4628 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 972us/step - loss: 0.4595 - accuracy: 0.7987\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.7922\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4640 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 978us/step - loss: 0.4568 - accuracy: 0.8006\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4771 - accuracy: 0.7953\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4628 - accuracy: 0.7985\n",
      "182/182 [==============================] - 0s 931us/step - loss: 0.4582 - accuracy: 0.7997\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4882 - accuracy: 0.7938\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4675 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 946us/step - loss: 0.4597 - accuracy: 0.7985\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.5005 - accuracy: 0.7855\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4688 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 907us/step - loss: 0.4601 - accuracy: 0.7982\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4869 - accuracy: 0.7967\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4674 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 886us/step - loss: 0.4608 - accuracy: 0.7972\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4948 - accuracy: 0.7948\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 913us/step - loss: 0.4585 - accuracy: 0.8000\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4849 - accuracy: 0.7978\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4667 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.7939\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4654 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4842 - accuracy: 0.7944\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4814 - accuracy: 0.7959\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 996us/step - loss: 0.4605 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4827 - accuracy: 0.7961\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 969us/step - loss: 0.4634 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.7955\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4654 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 948us/step - loss: 0.4597 - accuracy: 0.7997\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4766 - accuracy: 0.7974\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4634 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 961us/step - loss: 0.4592 - accuracy: 0.7995\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4778 - accuracy: 0.7976\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 955us/step - loss: 0.4596 - accuracy: 0.7987\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4777 - accuracy: 0.7971\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4633 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 969us/step - loss: 0.4608 - accuracy: 0.7986\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4778 - accuracy: 0.7972\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4640 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8009\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4774 - accuracy: 0.7973\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4638 - accuracy: 0.7985\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7996\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4930 - accuracy: 0.7940\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4862 - accuracy: 0.7980\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4695 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4882 - accuracy: 0.7961\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4700 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4908 - accuracy: 0.7973\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4692 - accuracy: 0.7977\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4895 - accuracy: 0.7966\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4683 - accuracy: 0.7980\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4837 - accuracy: 0.7973\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4659 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 981us/step - loss: 0.4678 - accuracy: 0.7982\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4821 - accuracy: 0.7979\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4666 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4836 - accuracy: 0.7975\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4670 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4839 - accuracy: 0.7964\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4851 - accuracy: 0.7973\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4672 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4837 - accuracy: 0.7949\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4648 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4798 - accuracy: 0.7979\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4648 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4816 - accuracy: 0.7967\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4650 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7985\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4798 - accuracy: 0.7971\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4654 - accuracy: 0.7977\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4839 - accuracy: 0.7932\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4651 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7984\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4931 - accuracy: 0.7895\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4658 - accuracy: 0.7985\n",
      "182/182 [==============================] - 0s 904us/step - loss: 0.4591 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.7905\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 909us/step - loss: 0.4590 - accuracy: 0.7985\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4867 - accuracy: 0.7946\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4664 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 891us/step - loss: 0.4601 - accuracy: 0.7977\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4900 - accuracy: 0.7874\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4667 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 874us/step - loss: 0.4575 - accuracy: 0.8001\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4846 - accuracy: 0.7943\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 873us/step - loss: 0.4585 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4904 - accuracy: 0.7847\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.4584 - accuracy: 0.7999\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.7901\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7986\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4759 - accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 883us/step - loss: 0.4595 - accuracy: 0.7989\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 880us/step - loss: 0.4575 - accuracy: 0.8006\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4799 - accuracy: 0.7951\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 952us/step - loss: 0.4584 - accuracy: 0.8000\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4759 - accuracy: 0.7978\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4627 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7995\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4754 - accuracy: 0.7974\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4629 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7988\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4806 - accuracy: 0.7950\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7988\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4844 - accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4644 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.8008\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4767 - accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4627 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.8003\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4915 - accuracy: 0.7908\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4673 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7987\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4857 - accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4671 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 912us/step - loss: 0.4656 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4862 - accuracy: 0.7964\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4657 - accuracy: 0.7985\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.4605 - accuracy: 0.7975\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.7903\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4860 - accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4670 - accuracy: 0.7980\n",
      "182/182 [==============================] - 0s 981us/step - loss: 0.4605 - accuracy: 0.7989\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4851 - accuracy: 0.7929\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4649 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7996\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4835 - accuracy: 0.7951\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4655 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4871 - accuracy: 0.7900\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.7935\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8003\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4821 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 994us/step - loss: 0.4610 - accuracy: 0.7984\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4766 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4633 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 995us/step - loss: 0.4618 - accuracy: 0.7990\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4766 - accuracy: 0.7970\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4637 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 971us/step - loss: 0.4600 - accuracy: 0.7984\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4815 - accuracy: 0.7941\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4641 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 977us/step - loss: 0.4600 - accuracy: 0.7986\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4785 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4639 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8009\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4778 - accuracy: 0.7966\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4641 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7998\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4954 - accuracy: 0.7904\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4683 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7985\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4891 - accuracy: 0.7971\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4691 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.5004 - accuracy: 0.7902\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4704 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4897 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4692 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4898 - accuracy: 0.7954\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4696 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 998us/step - loss: 0.4782 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4888 - accuracy: 0.7944\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4686 - accuracy: 0.7979\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4842 - accuracy: 0.7974\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4669 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4896 - accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4672 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4927 - accuracy: 0.7925\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.7977\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4876 - accuracy: 0.7957\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4682 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4797 - accuracy: 0.7973\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4653 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4815 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4646 - accuracy: 0.7986\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4894 - accuracy: 0.7913\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4662 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4804 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4666 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4809 - accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4653 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.6524 - accuracy: 0.6473\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5664 - accuracy: 0.7630\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4769 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5344 - accuracy: 0.7707\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4765 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5308 - accuracy: 0.7821\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4752 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5416 - accuracy: 0.7836\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5023 - accuracy: 0.7975\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.7748\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5212 - accuracy: 0.7916\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5242 - accuracy: 0.7805\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4707 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7753\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4732 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7770\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.7925\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.7736\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7986\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7982\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7830\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7865\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5229 - accuracy: 0.7947\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.7802\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4808 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5829 - accuracy: 0.7372\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5515 - accuracy: 0.7683\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.7797\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5274 - accuracy: 0.7845\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.7931\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4729 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5422 - accuracy: 0.7791\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5207 - accuracy: 0.7822\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7694\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7745\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7982\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7716\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 6ms/step - loss: 0.5148 - accuracy: 0.7890\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7977\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.7917\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.7698\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4729 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5486 - accuracy: 0.7956\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4866 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5701 - accuracy: 0.7434\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4895 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7966\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4803 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5344 - accuracy: 0.7908\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4836 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5310 - accuracy: 0.7959\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5401 - accuracy: 0.7824\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4789 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5277 - accuracy: 0.7936\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4764 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5185 - accuracy: 0.7938\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4773 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5368 - accuracy: 0.7899\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4799 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5490 - accuracy: 0.7788\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4753 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5198 - accuracy: 0.7910\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4729 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5312 - accuracy: 0.7787\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4723 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5342 - accuracy: 0.7745\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4729 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.5346 - accuracy: 0.7788\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.4764 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.5109 - accuracy: 0.7968\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.4732 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.7776\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4737 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5453 - accuracy: 0.7698\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4782 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5104 - accuracy: 0.7966\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4728 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5429 - accuracy: 0.7746\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4818 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5862 - accuracy: 0.7119\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5319 - accuracy: 0.7828\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4721 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.7970\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4708 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5143 - accuracy: 0.7913\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4715 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7979\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5301 - accuracy: 0.7852\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4718 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7907\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5061 - accuracy: 0.7921\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4681 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.7748\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.7902\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7977\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7968\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7977\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7992\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7920\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7710\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4829 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7773\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4812 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5542 - accuracy: 0.7629\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4840 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7644\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.7764\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5190 - accuracy: 0.7942\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4728 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5518 - accuracy: 0.7458\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4750 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7720\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7933\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4727 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7769\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7984\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7947\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7812\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7889\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5164 - accuracy: 0.7911\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.7832\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4708 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7988\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5479 - accuracy: 0.7859\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5351 - accuracy: 0.7937\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4826 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5439 - accuracy: 0.7800\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4835 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5524 - accuracy: 0.7715\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4862 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5190 - accuracy: 0.7973\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4801 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5323 - accuracy: 0.7853\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5320 - accuracy: 0.7927\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4763 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5229 - accuracy: 0.7948\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4762 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5375 - accuracy: 0.7827\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4794 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5350 - accuracy: 0.7811\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4790 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5265 - accuracy: 0.7879\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5362 - accuracy: 0.7664\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4755 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5108 - accuracy: 0.7977\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4722 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5313 - accuracy: 0.7825\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4759 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.5123 - accuracy: 0.7933\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.4729 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5454 - accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4771 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.7863\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4732 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5428 - accuracy: 0.7772\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4771 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.7111\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4853 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5285 - accuracy: 0.7937\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4773 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5097 - accuracy: 0.7968\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5112 - accuracy: 0.7968\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5242 - accuracy: 0.7847\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4708 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7973\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5293 - accuracy: 0.7883\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4728 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.6666\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7984\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7898\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7986\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7744\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.7970\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5914 - accuracy: 0.7431\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7854\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.7985\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7975\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5646 - accuracy: 0.7404\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5303 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5069 - accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5127 - accuracy: 0.7956\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7930\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7842\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4759 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4994 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4710 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5038 - accuracy: 0.7949\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4703 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.7730\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5488 - accuracy: 0.7497\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4722 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5206 - accuracy: 0.7792\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5108 - accuracy: 0.7942\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5490 - accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4861 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5406 - accuracy: 0.7867\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4797 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7885\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4807 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.7872\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4814 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5286 - accuracy: 0.7970\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5440 - accuracy: 0.7800\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5351 - accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5610 - accuracy: 0.7552\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4789 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5422 - accuracy: 0.7805\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4792 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5274 - accuracy: 0.7964\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4758 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5129 - accuracy: 0.7946\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4739 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5221 - accuracy: 0.7831\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4737 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5153 - accuracy: 0.7941\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4716 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5324 - accuracy: 0.7822\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4744 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.5150 - accuracy: 0.7947\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 10ms/step - loss: 0.4713 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5687 - accuracy: 0.7847\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.5324 - accuracy: 0.7936\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.7445\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.6852 - accuracy: 0.5665\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.5734 - accuracy: 0.7616\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5592 - accuracy: 0.7785\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5475 - accuracy: 0.7925\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5595 - accuracy: 0.7833\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7244\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.7972\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5356 - accuracy: 0.7873\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4792 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5833 - accuracy: 0.7129\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4818 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5671 - accuracy: 0.7526\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4813 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7549\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4807 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.7884\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5705 - accuracy: 0.7836\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4993 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5976 - accuracy: 0.7248\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5715 - accuracy: 0.7808\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4950 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5918 - accuracy: 0.7416\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5029 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6453 - accuracy: 0.6731\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7966\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5896 - accuracy: 0.7484\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4956 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5784 - accuracy: 0.7666\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4908 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5668 - accuracy: 0.7630\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4899 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5615 - accuracy: 0.7749\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4891 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5788 - accuracy: 0.7372\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4887 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5479 - accuracy: 0.7924\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4868 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5627 - accuracy: 0.7589\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4826 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5403 - accuracy: 0.7904\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4783 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5367 - accuracy: 0.7903\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4816 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5409 - accuracy: 0.7893\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4818 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.6025 - accuracy: 0.7531\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.5002 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.6036 - accuracy: 0.7412\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5059 - accuracy: 0.7980\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5860 - accuracy: 0.7691\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5005 - accuracy: 0.7980\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5650 - accuracy: 0.7907\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5036 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.6592 - accuracy: 0.6929\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5274 - accuracy: 0.7949\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.5830 - accuracy: 0.7722\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4902 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5874 - accuracy: 0.7466\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4905 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5586 - accuracy: 0.7786\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4882 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5871 - accuracy: 0.7711\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4963 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5586 - accuracy: 0.7695\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4928 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.5394 - accuracy: 0.7925\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4833 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7981\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5539 - accuracy: 0.7825\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4845 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7970\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5450 - accuracy: 0.7960\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4813 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5320 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4817 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5756 - accuracy: 0.7590\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4893 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.7873\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.7792\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4933 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.7889\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.7980\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5723 - accuracy: 0.7765\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5728 - accuracy: 0.7748\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5406 - accuracy: 0.7911\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5545 - accuracy: 0.7692\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4852 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5704 - accuracy: 0.7642\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4889 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5997 - accuracy: 0.7242\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5441 - accuracy: 0.7782\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5312 - accuracy: 0.7840\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4751 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5881 - accuracy: 0.7030\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4877 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5523 - accuracy: 0.7683\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4802 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5437 - accuracy: 0.7744\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4774 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5170 - accuracy: 0.7951\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4768 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5926 - accuracy: 0.7648\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5081 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5409 - accuracy: 0.7982\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4861 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5820 - accuracy: 0.7596\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4931 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5735 - accuracy: 0.7827\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4932 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6002 - accuracy: 0.7374\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4978 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5778 - accuracy: 0.7721\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4877 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6029 - accuracy: 0.7189\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4911 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5403 - accuracy: 0.7870\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4851 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5447 - accuracy: 0.7926\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4847 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5312 - accuracy: 0.7925\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4838 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5497 - accuracy: 0.7871\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4844 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5483 - accuracy: 0.7731\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4813 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5502 - accuracy: 0.7815\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4811 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5453 - accuracy: 0.7821\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4839 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5514 - accuracy: 0.7766\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4818 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.6000 - accuracy: 0.7453\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5084 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5902 - accuracy: 0.7609\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5019 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5630 - accuracy: 0.7933\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4969 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5790 - accuracy: 0.7733\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5034 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.6077 - accuracy: 0.7477\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5077 - accuracy: 0.7977\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.5933 - accuracy: 0.7397\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4917 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.5336 - accuracy: 0.7976\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4862 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5497 - accuracy: 0.7920\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4881 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 0.5524 - accuracy: 0.7962\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4873 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5489 - accuracy: 0.7951\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4883 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5365 - accuracy: 0.7891\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.4820 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5314 - accuracy: 0.7901\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4791 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5558 - accuracy: 0.7810\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4848 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5809 - accuracy: 0.7413\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4897 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5543 - accuracy: 0.7824\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4851 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5510 - accuracy: 0.7774\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6126 - accuracy: 0.7149\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4984 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6534 - accuracy: 0.6500\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5109 - accuracy: 0.7980\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5350 - accuracy: 0.7954\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4886 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5434 - accuracy: 0.7941\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4944 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5668 - accuracy: 0.7719\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4843 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7640\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4893 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5628 - accuracy: 0.7811\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4870 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5652 - accuracy: 0.7801\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4865 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5374 - accuracy: 0.7906\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4845 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5709 - accuracy: 0.7291\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4821 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5750 - accuracy: 0.7475\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4819 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5422 - accuracy: 0.7939\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4795 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7972\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5631 - accuracy: 0.7418\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4814 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.7822\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4792 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5783 - accuracy: 0.7707\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5046 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7051 - accuracy: 0.5759\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5274 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5753 - accuracy: 0.7696\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4982 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5548 - accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4905 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5733 - accuracy: 0.7736\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4945 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.5467 - accuracy: 0.7906\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4843 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.5519 - accuracy: 0.7874\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4849 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5461 - accuracy: 0.7908\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4873 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 0.5578 - accuracy: 0.7762\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4862 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.5891 - accuracy: 0.7316\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4891 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.5347 - accuracy: 0.7947\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4791 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5892 - accuracy: 0.7346\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4829 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5422 - accuracy: 0.7805\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4784 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5898 - accuracy: 0.7171\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4895 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5646 - accuracy: 0.7639\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4815 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.5568 - accuracy: 0.7974\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4948 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.6393 - accuracy: 0.7290\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.5100 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.5796 - accuracy: 0.7801\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4943 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.6211 - accuracy: 0.7641\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.5082 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.6181 - accuracy: 0.7346\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4992 - accuracy: 0.7977\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.6165 - accuracy: 0.7378\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.5000 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.6129 - accuracy: 0.7401\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.5050 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.5905 - accuracy: 0.7344\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4959 - accuracy: 0.7980\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.5710 - accuracy: 0.7728\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4876 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5624 - accuracy: 0.7827\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.4922 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 20ms/step - loss: 0.5740 - accuracy: 0.7721\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.4893 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7981\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 20ms/step - loss: 0.5446 - accuracy: 0.7844\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.4838 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5571 - accuracy: 0.7771\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.4831 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5612 - accuracy: 0.7566\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.4856 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5417 - accuracy: 0.7914\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4825 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "906/906 [==============================] - 3s 3ms/step - loss: 0.4740 - accuracy: 0.7973\n",
      "Epoch 2/45\n",
      "906/906 [==============================] - 3s 3ms/step - loss: 0.4627 - accuracy: 0.7989\n",
      "Best params: {'batch_size': 1000, 'epochs': 45, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 25}\n",
      "Best average accuracy: 0.7998762965202332\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# KerasClassifier을 위한 build_fn 정의 (build_model)\n",
    "# 신경망 model 생성\n",
    "def build_model(num_layers, num_nodes, loss):\n",
    "    # Define and compile the model\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(num_nodes, input_dim=27, activation='relu'))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(num_nodes, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='Adam', loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# KFold validation 사용\n",
    "# k: n_splits=5\n",
    "kfold = KFold(random_state=30,\n",
    "           n_splits=5,\n",
    "           shuffle=True\n",
    "          )\n",
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model)\n",
    "\n",
    "# 최적 hyperparameter을 찾기위한 gridsearchCV를 위한 parameter\n",
    "parameters = {\n",
    "    'batch_size': [1000,5000,10000],\n",
    "    'epochs': [45,60,100],\n",
    "    'num_layers': [2, 3, 5],\n",
    "    'num_nodes': [15, 20, 25],\n",
    "    'loss':[\"binary_crossentropy\"]\n",
    "    }\n",
    "# GridSearchCV 생성\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           cv = kfold)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "# GridSearchCV fit 시작\n",
    "grid_search.fit(x_train, y_train, callbacks=[early_stopping])\n",
    "# 최적의 param\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "# 최적의 param일 경우 최적의 accuracy\n",
    "print(f\"Best average accuracy: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search를 수행했을 경우의 각각의 결과s\n",
    "# Best params(PCA1_feature86): {'batch_size': 1000, 'epochs': 60, 'loss': 'binary_crossentropy', 'num_layers':s 2, 'num_nodes': 40\n",
    "# Best params(PCA95_feature50): {'batch_size': 1000, 'epochs': 100, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "# Best params(PCA95_feature50,reversed): {'batch_size': 1000, 'epochs': 60, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "\n",
    "result = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 위의 모델을 생성한 결과를 바탕으로 hyperparameter를 설정한 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 모델(without EarlyStopping)\n",
    "- avg accuracy: 0.8004517912864685\n",
    "- avg F1-score: 0.8004525303840637\n",
    "- avg recall: 0.8004526019096374\n",
    "- avg precision: 0.8004526019096374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "   print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772684     0\n",
       "255879     1\n",
       "670719     0\n",
       "1000896    0\n",
       "232159     0\n",
       "          ..\n",
       "954574     0\n",
       "482540     0\n",
       "404219     1\n",
       "659201     0\n",
       "279311     0\n",
       "Name: loan_status, Length: 905345, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1000, 'epochs': 45, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 25}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\\n            9,\\n       ...\\n       905330, 905331, 905332, 905333, 905338, 905339, 905340, 905341, 905342,\\n       905344],\\n      dtype='int32', length=724276)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(x_train, y_train_reshaped):\n\u001b[1;32m---> 20\u001b[0m     X_train_fold, X_val_fold \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, x_train[val_index]\n\u001b[0;32m     21\u001b[0m     Y_train_fold, Y_val_fold \u001b[38;5;241m=\u001b[39m y_train_reshaped[train_index], y_train_reshaped[val_index]\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\\n            9,\\n       ...\\n       905330, 905331, 905332, 905333, 905338, 905339, 905340, 905341, 905342,\\n       905344],\\n      dtype='int32', length=724276)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Best params: {'batch_size': 1000, 'epochs': 45, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 25}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "# best_params = grid_search.best_params_\n",
    "best_params = {'batch_size': 1000, 'epochs': 45, 'loss': 'binary_crossentropy', 'num_layers': 2, 'num_nodes': 25}\n",
    "print(best_params)\n",
    "y_train_reshaped = np.reshape(y_train,(-1))\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=27, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "for train_index, val_index in kf.split(x_train, y_train_reshaped):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train_reshaped[train_index], y_train_reshaped[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, \n",
    "              Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping])\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc= model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "\n",
    "    pred = model.predict(X_val_fold)\n",
    "    preds_1d = pred.flatten()\n",
    "    pred = np.where(preds_1d >=0.3, 1 , 0)\n",
    "    valid_f1s.append(f1_score(Y_val_fold, pred))\n",
    "    valid_precisions.append(precision_score(Y_val_fold, pred))\n",
    "    valid_recalls.append(recall_score(Y_val_fold, pred))\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5\n",
    "- avg Validation accuracy: 0.7999326229095459\n",
    "- avg Validation F1-score: 0.07847019961778763\n",
    "- avg Validation recall: 0.04220624698973309\n",
    "- avg Validation precision: 0.5672307197587909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7074/7074 [==============================] - 4s 614us/step\n",
      "###################################\n",
      "Validation accuracy: 0.8009472600591154\n",
      "Validation F1-score: 0.09566631204961962\n",
      "Validation recall: 0.05210223670113912\n",
      "Validation precision: 0.583782459578638\n"
     ]
    }
   ],
   "source": [
    "valid_pred = model.predict(x_validation)\n",
    "valid_preds_1d = valid_pred.flatten()\n",
    "valid_pred = np.where(valid_preds_1d>0.5, 1, 0)\n",
    "print(\"###################################\")\n",
    "print(\"Validation accuracy:\", accuracy_score(y_validation, valid_pred))\n",
    "print(\"Validation F1-score:\", f1_score(y_validation, valid_pred))\n",
    "print(\"Validation recall:\", recall_score(y_validation, valid_pred))\n",
    "print(\"Validation precision:\", precision_score(y_validation, valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dnn_models/log_transformed/pca95_feature27/with_earlystopping001_0425(minmaxscaler).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 model(with EarlyStopping)\n",
    "### earlystopping: min_delta was 0.001\n",
    "- avg accuracy: 0.7999342799186706\n",
    "- avg F1-score: 0.7999348163604736\n",
    "- avg recall: 0.7999348998069763\n",
    "- avg precision: 0.7999348998069763\n",
    "\n",
    "### earlystopping: min_delta was 0.0001\n",
    "- avg accuracy: 0.80015869140625\n",
    "- avg F1-score: 0.8001592040061951\n",
    "- avg recall: 0.8001593112945556\n",
    "- avg precision: 0.8001593112945556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4687 - accuracy: 0.7984 - f1_score: 0.7984 - recall: 0.7984 - precision: 0.7984\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4575 - accuracy: 0.7998 - f1_score: 0.7999 - recall: 0.7999 - precision: 0.7999\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4541 - accuracy: 0.8005 - f1_score: 0.8006 - recall: 0.8006 - precision: 0.8006\n",
      "===================================\n",
      "Validation accuracy: 0.8005456328392029\n",
      "Validation F1-score: 0.8005503416061401\n",
      "Validation recall: 0.8005504608154297\n",
      "Validation precision: 0.8005504608154297\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4555 - accuracy: 0.8004 - f1_score: 0.8004 - recall: 0.8004 - precision: 0.8004\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4542 - accuracy: 0.8008 - f1_score: 0.8008 - recall: 0.8008 - precision: 0.8008\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4532 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "===================================\n",
      "Validation accuracy: 0.8019374012947083\n",
      "Validation F1-score: 0.801925778388977\n",
      "Validation recall: 0.8019258975982666\n",
      "Validation precision: 0.8019258975982666\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4531 - accuracy: 0.8016 - f1_score: 0.8016 - recall: 0.8016 - precision: 0.8016\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4524 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4542 - accuracy: 0.8006 - f1_score: 0.8006 - recall: 0.8006 - precision: 0.8006\n",
      "===================================\n",
      "Validation accuracy: 0.8005732893943787\n",
      "Validation F1-score: 0.8005940914154053\n",
      "Validation recall: 0.8005942106246948\n",
      "Validation precision: 0.8005942106246948\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4521 - accuracy: 0.8007 - f1_score: 0.8007 - recall: 0.8007 - precision: 0.8007\n",
      "===================================\n",
      "Validation accuracy: 0.8007334470748901\n",
      "Validation F1-score: 0.8007299900054932\n",
      "Validation recall: 0.8007301092147827\n",
      "Validation precision: 0.8007301092147827\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4524 - accuracy: 0.8014 - f1_score: 0.8014 - recall: 0.8014 - precision: 0.8014\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.8018 - f1_score: 0.8018 - recall: 0.8018 - precision: 0.8018\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4499 - accuracy: 0.8026 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "===================================\n",
      "Validation accuracy: 0.8026387691497803\n",
      "Validation F1-score: 0.8026190400123596\n",
      "Validation recall: 0.8026190996170044\n",
      "Validation precision: 0.8026190996170044\n",
      "###################################\n",
      "avg Validation accuracy: 0.8012857079505921\n",
      "avg Validation F1-score: 0.801283848285675\n",
      "avg Validation recall: 0.8012839555740356\n",
      "avg Validation precision: 0.8012839555740356\n"
     ]
    }
   ],
   "source": [
    "# # 최고의 파라미터 : {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=86, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss=best_params['loss'], optimizer='Adam', metrics=[\"accuracy\", f1_score, recall, precision])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc, valid_f1, valid_recall, valid_precision = model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    valid_f1s.append(valid_f1)\n",
    "    valid_recalls.append(valid_recall)\n",
    "    valid_precisions.append(valid_precision)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "    print(\"Validation F1-score:\", valid_f1)\n",
    "    print(\"Validation recall:\", valid_recall)\n",
    "    print(\"Validation precision:\", valid_precision)\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n",
    "model.save('dnn_models/non_log_transformed/pca1_feature86/with_earlystopping_001_0421.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4725 - accuracy: 0.7965 - f1_score: 0.7965 - recall: 0.7965 - precision: 0.7965\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.7998 - f1_score: 0.7998 - recall: 0.7998 - precision: 0.7998\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4563 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "===================================\n",
      "Validation accuracy: 0.8016557097434998\n",
      "Validation F1-score: 0.8016602993011475\n",
      "Validation recall: 0.801660418510437\n",
      "Validation precision: 0.801660418510437\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4560 - accuracy: 0.8004 - f1_score: 0.8004 - recall: 0.8004 - precision: 0.8004\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4545 - accuracy: 0.8009 - f1_score: 0.8009 - recall: 0.8009 - precision: 0.8009\n",
      "5659/5659 [==============================] - 7s 1ms/step - loss: 0.4535 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "===================================\n",
      "Validation accuracy: 0.8019981384277344\n",
      "Validation F1-score: 0.801986575126648\n",
      "Validation recall: 0.8019866347312927\n",
      "Validation precision: 0.8019866347312927\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.8015 - f1_score: 0.8015 - recall: 0.8015 - precision: 0.8015\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4533 - accuracy: 0.8011 - f1_score: 0.8011 - recall: 0.8011 - precision: 0.8011\n",
      "===================================\n",
      "Validation accuracy: 0.8010979294776917\n",
      "Validation F1-score: 0.801118791103363\n",
      "Validation recall: 0.801118791103363\n",
      "Validation precision: 0.801118791103363\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.8016 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4521 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4517 - accuracy: 0.8013 - f1_score: 0.8013 - recall: 0.8013 - precision: 0.8013\n",
      "===================================\n",
      "Validation accuracy: 0.8013133406639099\n",
      "Validation F1-score: 0.8013017773628235\n",
      "Validation recall: 0.801301896572113\n",
      "Validation precision: 0.801301896572113\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.8018 - f1_score: 0.8018 - recall: 0.8018 - precision: 0.8018\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4517 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4502 - accuracy: 0.8021 - f1_score: 0.8021 - recall: 0.8021 - precision: 0.8021\n",
      "===================================\n",
      "Validation accuracy: 0.8020754456520081\n",
      "Validation F1-score: 0.8020557761192322\n",
      "Validation recall: 0.802055835723877\n",
      "Validation precision: 0.802055835723877\n",
      "###################################\n",
      "avg Validation accuracy: 0.8016281127929688\n",
      "avg Validation F1-score: 0.8016246438026429\n",
      "avg Validation recall: 0.8016247153282166\n",
      "avg Validation precision: 0.8016247153282166\n"
     ]
    }
   ],
   "source": [
    "# # 최고의 파라미터 : {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=86, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss=best_params['loss'], optimizer='Adam', metrics=[\"accuracy\", f1_score, recall, precision])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.0001)\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc, valid_f1, valid_recall, valid_precision = model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    valid_f1s.append(valid_f1)\n",
    "    valid_recalls.append(valid_recall)\n",
    "    valid_precisions.append(valid_precision)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "    print(\"Validation F1-score:\", valid_f1)\n",
    "    print(\"Validation recall:\", valid_recall)\n",
    "    print(\"Validation precision:\", valid_precision)\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n",
    "model.save('dnn_models/non_log_transformed/pca1_feature86/with_earlystopping_0001_0421.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
