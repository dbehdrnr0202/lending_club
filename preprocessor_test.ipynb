{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from typing import Union, List\n","'''\n","TODO\n","1) addr_state 변수 설정해야한다\n","2) 결측치에서 'acc_open_past_24mths', 'avg_cur_bal': 확인필요\n","'''\n","class Preprocessor:\n","    def __init__(self):\n","        self.file_path = \"\"\n","        self.folder_path = \"\"\n","        self.df = pd.DataFrame()\n","    \n","    def __init__(self, data_file_path:str=\"\", folder_path:str=\"\"):\n","        self.file_path = data_file_path\n","        self.folder_path = folder_path\n","        self.df = pd.DataFrame()\n","        \n","    def load_origin_file(self, file_path:str)->None:\n","        if file_path!=\"\":\n","            self.file_path = file_path\n","        self.df = pd.read_csv(self.file_path)\n","        \n","    def drop_columns(self, drop_columns_file_path:str = \"drop_columns_0402.txt\")->None:\n","        with open(drop_columns_file_path, mode='r') as f:\n","            drop_fields = f.readlines()\n","            drop_fields = [drop_field.strip('\\n') for drop_field in drop_fields]\n","        self.df.drop(columns=drop_fields, inplace=True)\n","    \n","    def __preprocess_target_variable(self, target_variable:str=\"loan_status\")->None:\n","        # loan_status가 \"current\", \"issued\", \"policy\" 인 행을 필터링하여 삭제\n","        modified_df = self.df[~self.df[target_variable].isin(['Current', 'Issued', 'Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off'])]\n","        # risk = 1, safe = 0 으로 처리\n","        modified_df.loc[modified_df['loan_status'].isin(['Fully Paid', 'In Grace Period']), 'loan_status'] = 0\n","        modified_df.loc[modified_df['loan_status'].isin(['Charged Off', 'Default', 'Late (16-30 days)', 'Late (31-120 days)']), 'loan_status'] = 1\n","        modified_df['loan_status'] = modified_df['loan_status'].astype('int')\n","        self.df = modified_df\n","        \n","    ## 5. 데이터 처리용 함수\n","    def __delete_suffix(self, term:str)->int:\n","        '''첫 단어만을 저장하는 함수'''\n","        term = term.strip().split()[0]\n","        return int(term)\n","\n","    def __delete_suffix_percentage(self, term:str)->float:\n","        '''%를 자르는 함수'''\n","        term = term.strip('%')\n","        return float(term)\n","    \n","    def __fill_na_with_value(self, columns:List[str], filling_value:Union[str, int])->None:\n","        '''\n","        df: dataframe to fill NA\n","        column_name : column name to change NA values\n","        filling_value : value type or just value to fill column's NA\n","        '''\n","        for column_name in columns:\n","            if filling_value==\"mode\":\n","                mode_value = self.df[column_name].mode()[0]\n","            elif filling_value==\"median\":\n","                mode_value = self.df[column_name].median()\n","            else:\n","                mode_value = filling_value\n","            self.df[column_name].fillna(mode_value, inplace=True)\n","        \n","    def __preprocessing_na(self)->None:\n","        '''\n","        'acc_open_past_24mths', 확인필요\n","        'avg_cur_bal', 확인필요\n","        '''\n","        ## 결측 처리\n","        # 결측 개수가 1천 건 이하인 경우는 해당 데이터(row) 삭제\n","        self.df.dropna(subset=['chargeoff_within_12_mths','collections_12_mths_ex_med','dti',\n","                                                'pub_rec_bankruptcies','revol_util','tax_liens'], inplace=True)\n","        \n","        # A1. 최빈값 대체\n","        self.__fill_na_with_value(columns=['mo_sin_old_il_acct', 'mths_since_recent_bc', 'mths_since_recent_inq', 'emp_length'], filling_value='mode')\n","        \n","        # A2. 중앙값 대체\n","        self.__fill_na_with_value(columns=['bc_open_to_buy'], filling_value='median')\n","        # B. 2015년 대체\n","        # is_after_2015 컬럼 생성. all_util 변수를 기준으로 사용\n","        self.df['is_after_2015'] = self.df['all_util'].apply(lambda x: 0 if pd.isnull(x) else 1)\n","        # 결측값을 0으로 채우기\n","        \n","        # C. 2012년 대체\n","        # is_after_2012 컬럼 생성. pct_tl_nvr_dlq 변수를 기준으로 사용\n","        self.df['is_after_2012'] = self.df['pct_tl_nvr_dlq'].apply(lambda x: 0 if pd.isnull(x) else 1)\n","        # D. 결측 0 대체\n","        self.__fill_na_with_value(columns=['annual_inc_joint','dti_joint','revol_bal_joint', 'open_acc_6m',\n","                                           'open_act_il', 'open_il_12m', 'open_il_24m', 'total_bal_il',\n","                                           'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_cu_tl', 'mths_since_rcnt_il',\n","                                           'tot_cur_bal', 'total_rev_hi_lim', 'mo_sin_old_rev_tl_op',\n","                                           'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'num_bc_sats', 'num_bc_tl',\n","                                           'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_il_tl',\n","                                           'num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_120dpd_2m','num_tl_30dpd',\n","                                           'num_tl_90g_dpd_24m','num_tl_op_past_12m','pct_tl_nvr_dlq','tot_hi_cred_lim','total_bal_ex_mort',\n","                                           'total_bc_limit','total_il_high_credit_limit'], filling_value=0)\n","        \n","        \n","    def __convert_object_to_numeric(self, column_name:str)->pd.DataFrame:\n","        unique_values = sorted(self.df[column_name].unique())\n","        value_map = {value:index for index, value in enumerate(unique_values)}\n","        self.df[column_name] = self.df[column_name].apply(lambda x:value_map.get(x))\n","        return self.df\n","    \n","    def __convert_object_to_one_hot(self, column_name:str)->None:\n","        encoded = pd.get_dummies(self.df[column_name])\n","        self.df = pd.concat([self.df, encoded], axis=1)\n","        self.df.drop(column_name, axis=1, inplace=True)\n","        \n","    def __preprocessing_objects(self)->None:\n","        ## TODO : 'addr_state' 필드 해결하기\n","        # term\n","        self.df['term'] = self.df['term'].apply(self.__delete_suffix)\n","        # emp_length\n","        self.df['emp_length'] = self.df['emp_length'].apply(lambda x: x.replace(' years','').replace(' year','').replace('+','').replace('< 1', '0'))\n","        self.df['emp_length'] = self.df['emp_length'].astype(int)\n","        # revol_util\n","        self.df['revol_util'] = self.df['revol_util'].apply(self.__delete_suffix_percentage)\n","        self.df['int_rate'] = self.df['int_rate'].apply(self.__delete_suffix_percentage)\n","        ## numeric\n","        # application_type\n","        self.df = self.__convert_object_to_numeric('application_type')\n","        # sub_grade\n","        self.df = self.__convert_object_to_numeric('sub_grade')\n","\n","        ## one-hot\n","        # home_ownership\n","        self.df['home_ownership'] = self.df['home_ownership'].replace(['ANY', 'OTHER', 'NONE'], 'OTHERS')\n","        self.__convert_object_to_one_hot('home_ownership')\n","        # purpose\n","        self.__convert_object_to_one_hot('purpose')\n","        # verification_status\n","        self.__convert_object_to_one_hot('verification_status')\n","        # addr_state : 해야함...\n","    def __Multicollinearity(self)->None:\n","        # self.df.drop(columns=['fico_range_low'], inplace=True)\n","        self.df['fico_avg'] = (self.df['fico_range_low'] + self.df['fico_range_high'])/2\n","        self.df.drop(columns=['fico_range_low', 'fico_range_high'], inplace=True)\n","\n","    def __log_transform(self):\n","        variables = [\n","          \"all_util\", \"annual_inc\", \"annual_inc_joint\", \"bc_open_to_buy\", # \"avg_cur_bal\",\n","          \"delinq_amnt\", \"dti\", \"max_bal_bc\", \"mo_sin_old_il_acct\", \"mo_sin_old_rev_tl_op\",\n","          \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\", \"mths_since_rcnt_il\",\n","          \"mths_since_recent_bc\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\", \"num_actv_rev_tl\",\n","          \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\", \"num_op_rev_tl\", \"num_rev_accts\",\n","          \"num_rev_tl_bal_gt_0\", \"num_sats\", \"open_acc\", \"open_acc_6m\", \"open_act_il\",\n","          \"open_il_12m\", \"open_il_24m\", \"open_rv_12m\", \"open_rv_24m\", \"pub_rec_bankruptcies\",\n","          \"revol_bal\", \"revol_bal_joint\", \"tax_liens\", \"tot_cur_bal\", \"tot_hi_cred_lim\",\n","          \"total_acc\", \"total_bal_ex_mort\", \"total_bal_il\", \"total_bc_limit\", \"total_cu_tl\",\n","          \"total_il_high_credit_limit\", \"total_rev_hi_lim\"\n","        ]\n","\n","        # 각 변수에 대해 로그 변환 수행 및 기존 변수 삭제\n","        for var in variables:\n","            # 로그 변환 후 변수 이름에 '_log'를 추가하여 새로운 변수 생성\n","            new_var = var + \"_log\"\n","            # 해당 변수가 0보다 큰 경우에만 로그 변환 수행하여 음수 무한대를 방지\n","            # 로그 변환 후에는 기존 값이 0인 경우 음수 무한대로 처리되므로 이에 대한 처리도 필요\n","            # 여기서 로그는 자연로그 (밑이 e인 로그)\n","            self.df[new_var] = np.log(self.df[var] + 1)  # 0이 아닌 값이어야 하므로 +1 추가\n","            # 기존 변수 삭제\n","            self.df.drop(columns=[var], inplace=True)\n","        return self.df\n","    \n","    def preprocess(self)->None:\n","        # loan_status 제외 모든 column이 결측치(na)인 행 제거 (1개 행 제거됨)\n","        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n","        self.__preprocess_target_variable()\n","        # 결측치 제거\n","        self.__preprocessing_na()\n","        ## object 처리하기\n","        self.__preprocessing_objects()\n","        ## 다중공선성 제거 - 0419 추가\n","        self.__Multicollinearity()\n","        ## 로그변환 - 0419 추가\n","        self.__log_transform()\n","        # index 재설정\n","        self.df.reset_index(drop=True, inplace=True)\n","        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n","        \n","    def get_df(self)->pd.DataFrame:\n","        return self.df"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["120620   -1.0\n","660029   -1.0\n","Name: dti, dtype: float64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["origin_df = pd.read_csv('data/lending_club_2020_test.csv')\n","origin_df[origin_df['dti']==origin_df['dti'].min()]['dti']"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_19000\\304576546.py:37: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  modified_df['loan_status'] = modified_df['loan_status'].astype('int')\n","C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_19000\\304576546.py:64: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  self.df[column_name].fillna(mode_value, inplace=True)\n","C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_19000\\304576546.py:64: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  self.df[column_name].fillna(mode_value, inplace=True)\n","c:\\Users\\Hi\\anaconda3\\envs\\tf_python_310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n","  result = getattr(ufunc, method)(*inputs, **kwargs)\n"]}],"source":["p = Preprocessor()\n","# lending_club_2020_train.csv 파일이 있는 절대 경로 혹은 상대 경로를 명시해주세요\n","p.load_origin_file(file_path=\"data/lending_club_2020_test.csv\")\n","# drop_columns_0410.txt 파일의 위치를 명시해주세요\n","p.drop_columns(drop_columns_file_path='texts/drop_columns_0411.txt')\n","# preprocess를 돌리면, addr_state를 제외한 object field 및, na(결측치) 처리됩니다.\n","p.preprocess()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["['inq_last_6mths']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["## 여기 뭔가가 이상함,,,\n","test_df = p.get_df()\n","test_df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["test_df[test_df['dti_log']!=test_df['dti_log'].min()].to_csv('data/modified_test.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
