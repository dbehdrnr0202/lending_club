{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/modified_0420_non_log.csv\")\n",
    "x_train = df.drop(columns=['loan_status', 'Unnamed: 0'])\n",
    "y_train = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = np.isnan(x_train).any(axis=1)\n",
    "x_train = x_train[~nan_indices]\n",
    "y_train = y_train[~nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaler 찾아보기\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11837584 0.18119859 0.2346223  0.2765454  0.31422626 0.34761015\n",
      " 0.37670842 0.40427562 0.42823748 0.44972255 0.47017965 0.4904205\n",
      " 0.50900491 0.52696055 0.54284285 0.55786735 0.5723495  0.58647353\n",
      " 0.60017332 0.61374041 0.62712457 0.64004547 0.65174334 0.66331782\n",
      " 0.67478054 0.68619253 0.69754838 0.7088998  0.72021919 0.73148252\n",
      " 0.74272496 0.75389511 0.76500835 0.7760844  0.78707082 0.79801543\n",
      " 0.80864987 0.8190369  0.82928607 0.83924327 0.84900517 0.85844246\n",
      " 0.86734653 0.87601505 0.88440554 0.89237889 0.90002141 0.90739231\n",
      " 0.91432519 0.92066463 0.92685471 0.93267462 0.93836049 0.94368548\n",
      " 0.94857446 0.95331609 0.95761997 0.96168493 0.96554233 0.96908419\n",
      " 0.97261061 0.97577021 0.97875345 0.98167098 0.98457031 0.98688383\n",
      " 0.98869454 0.99046357 0.9917621  0.99286154 0.99379974 0.9945636\n",
      " 0.99531436 0.9959725  0.99660094 0.99717484 0.99771822 0.99817858\n",
      " 0.99862292 0.99902854 0.99929771 0.99951082 0.99967258 0.99981108\n",
      " 0.99991111 1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_components_from_pca(scaled_data:pd.DataFrame, threshold:float) -> int:\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_data)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "    print(cumulative_explained_variance)\n",
    "    # 누적 설명 분산 시각화\n",
    "    plt.plot(cumulative_explained_variance, marker='o', linestyle='-')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('Cumulative Explained Variance by Number of Components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # 적절한 주성분 개수 선택\n",
    "    n_components = np.argmax(cumulative_explained_variance >= threshold) + 1\n",
    "    return n_components\n",
    "get_n_components_from_pca(X_scaled, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA로 차원 축소\n",
    "pca = PCA(n_components=86)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "x_train = X_pca.astype('float32')\n",
    "# stratify로 학습에 용이하게 비율 유지\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train, 2).astype(int)\n",
    "y_validation=to_categorical(y_validation, 2).astype(int)\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# encoder = OneHotEncoder()\n",
    "# y_train = y_train.values\n",
    "# y_train = encoder.fit_transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())    \n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 아래 칸은 최적의 hyperparameter를 찾기 위해서 실행하는 칸이므로, 실행할 필요 없습니다.\n",
    "\n",
    "모델만을 알고싶다면 넘어가세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.7851\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 943us/step - loss: 0.4577 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4942 - accuracy: 0.7898\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 942us/step - loss: 0.4576 - accuracy: 0.8001\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4860 - accuracy: 0.7959\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7979\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4918 - accuracy: 0.7887\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 966us/step - loss: 0.4579 - accuracy: 0.7986\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.5076 - accuracy: 0.7802\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.4565 - accuracy: 0.8003\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4772 - accuracy: 0.7951\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8012\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4868 - accuracy: 0.7893\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 964us/step - loss: 0.4556 - accuracy: 0.8011\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4731 - accuracy: 0.7980\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4586 - accuracy: 0.7999\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7986\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4909 - accuracy: 0.7918\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.7995\n",
      "182/182 [==============================] - 0s 986us/step - loss: 0.4569 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4780 - accuracy: 0.7947\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 993us/step - loss: 0.4549 - accuracy: 0.8007\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.7971\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4577 - accuracy: 0.7997\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8016\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4705 - accuracy: 0.7970\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4577 - accuracy: 0.7999\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8014\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4682 - accuracy: 0.7988\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4569 - accuracy: 0.8004\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7993\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4711 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4575 - accuracy: 0.8002\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4731 - accuracy: 0.7963\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4580 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.8015\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.7901\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7984\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.7880\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7995\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4890 - accuracy: 0.7954\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4850 - accuracy: 0.7970\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 954us/step - loss: 0.4639 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.7927\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4655 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7993\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4759 - accuracy: 0.7968\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4605 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8002\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4742 - accuracy: 0.7975\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4600 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8009\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4739 - accuracy: 0.7980\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4594 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7994\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4775 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4600 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7984\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4760 - accuracy: 0.7966\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4602 - accuracy: 0.7991\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8008\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4719 - accuracy: 0.7975\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4580 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8007\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4759 - accuracy: 0.7948\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4589 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8008\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4737 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4582 - accuracy: 0.7997\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7975\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4741 - accuracy: 0.7971\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4585 - accuracy: 0.7997\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4746 - accuracy: 0.7953\n",
      "Epoch 2/45\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4591 - accuracy: 0.7995\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8008\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4849 - accuracy: 0.7922\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4643 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7985\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4920 - accuracy: 0.7899\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4640 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8002\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4798 - accuracy: 0.7983\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4623 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4933 - accuracy: 0.7905\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4664 - accuracy: 0.7984\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7975\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4824 - accuracy: 0.7951\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4638 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.7977\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4586 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8006\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.7936\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8005\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4764 - accuracy: 0.7944\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4585 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 2ms/step - loss: 0.4795 - accuracy: 0.7953\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4792 - accuracy: 0.7946\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4595 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8013\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4740 - accuracy: 0.7958\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4581 - accuracy: 0.7997\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8005\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4814 - accuracy: 0.7920\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4587 - accuracy: 0.7994\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8019\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.7977\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4571 - accuracy: 0.8001\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7999\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4754 - accuracy: 0.7951\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.7999\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4691 - accuracy: 0.7978\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4577 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.8019\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4903 - accuracy: 0.7935\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4656 - accuracy: 0.7982\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7988\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4830 - accuracy: 0.7969\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7995\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4848 - accuracy: 0.7965\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4664 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4901 - accuracy: 0.7954\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4643 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7970\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4834 - accuracy: 0.7951\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4665 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4771 - accuracy: 0.7969\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4603 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8002\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4801 - accuracy: 0.7948\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4613 - accuracy: 0.7981\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.8008\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4758 - accuracy: 0.7971\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4598 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7972\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4749 - accuracy: 0.7977\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4600 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7986\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4766 - accuracy: 0.7967\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4605 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8013\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4712 - accuracy: 0.7979\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4588 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.8017\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4757 - accuracy: 0.7943\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4588 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8005\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4717 - accuracy: 0.7980\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4579 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7987\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4722 - accuracy: 0.7976\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4585 - accuracy: 0.7997\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4791 - accuracy: 0.7910\n",
      "Epoch 2/60\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.4588 - accuracy: 0.7995\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8020\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4952 - accuracy: 0.7857\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.7983\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4901 - accuracy: 0.7943\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4637 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7999\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4866 - accuracy: 0.7928\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4636 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7979\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4896 - accuracy: 0.7945\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4634 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7988\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4819 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4623 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8006\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4742 - accuracy: 0.7968\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4594 - accuracy: 0.7994\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8013\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4733 - accuracy: 0.7971\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4591 - accuracy: 0.7992\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8009\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4756 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4590 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4909 - accuracy: 0.7867\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4599 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4592 - accuracy: 0.7990\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8016\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4691 - accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.8000\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8016\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4779 - accuracy: 0.7943\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8010\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4713 - accuracy: 0.7979\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4572 - accuracy: 0.8000\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7995\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4691 - accuracy: 0.7982\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4576 - accuracy: 0.8000\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7999\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4716 - accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4578 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8019\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4859 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4674 - accuracy: 0.7978\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4901 - accuracy: 0.7922\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4673 - accuracy: 0.7976\n",
      "182/182 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4842 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4648 - accuracy: 0.7988\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4929 - accuracy: 0.7917\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4649 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7970\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4848 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4669 - accuracy: 0.7976\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4807 - accuracy: 0.7915\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4603 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7995\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4736 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4602 - accuracy: 0.7987\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8003\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4731 - accuracy: 0.7979\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4595 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4736 - accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4600 - accuracy: 0.7993\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7972\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4819 - accuracy: 0.7916\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4607 - accuracy: 0.7989\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8003\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4716 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.4586 - accuracy: 0.7996\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7994\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4722 - accuracy: 0.7970\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.4583 - accuracy: 0.7994\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8007\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.4705 - accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.4578 - accuracy: 0.7998\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7992\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4734 - accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.4583 - accuracy: 0.8000\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7986\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 4s 4ms/step - loss: 0.4796 - accuracy: 0.7907\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4593 - accuracy: 0.7994\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8009\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7847\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7579\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.7975\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5224 - accuracy: 0.7959\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4768 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5318 - accuracy: 0.7799\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4823 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5625 - accuracy: 0.7603\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7976\n",
      "37/37 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4929 - accuracy: 0.7964\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4648 - accuracy: 0.7986\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8000\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5104 - accuracy: 0.7802\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4685 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5220 - accuracy: 0.7724\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7967\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.7811\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7975\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5588 - accuracy: 0.7503\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4772 - accuracy: 0.7968\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7992\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4964 - accuracy: 0.7917\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4647 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7998\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.5015 - accuracy: 0.7886\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4655 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8010\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5145 - accuracy: 0.7795\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4668 - accuracy: 0.7988\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7979\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5001 - accuracy: 0.7851\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4663 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7971\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.4963 - accuracy: 0.7912\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4658 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8008\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5380 - accuracy: 0.7762\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4834 - accuracy: 0.7977\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5291 - accuracy: 0.7920\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4788 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5575 - accuracy: 0.7494\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4827 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5506 - accuracy: 0.7502\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4825 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5498 - accuracy: 0.7585\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5072 - accuracy: 0.7905\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4698 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7984\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5498 - accuracy: 0.7498\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4763 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5276 - accuracy: 0.7694\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4723 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4999 - accuracy: 0.7922\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4677 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7969\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4989 - accuracy: 0.7962\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4687 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 0.5100 - accuracy: 0.7848\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4684 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.4987 - accuracy: 0.7909\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4655 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8007\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5113 - accuracy: 0.7823\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4675 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7974\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5035 - accuracy: 0.7835\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4662 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7980\n",
      "Epoch 1/45\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5188 - accuracy: 0.7763\n",
      "Epoch 2/45\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4684 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7999\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7837\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4762 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7985\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.5800 - accuracy: 0.7418\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.4841 - accuracy: 0.7959\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.6089 - accuracy: 0.6964\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7664\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7648\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.7954\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4656 - accuracy: 0.7985\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5270 - accuracy: 0.7781\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4741 - accuracy: 0.7971\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.7519\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4725 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7964\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5031 - accuracy: 0.7885\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7973\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.7515\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4757 - accuracy: 0.7967\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7992\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5052 - accuracy: 0.7822\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4679 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.7825\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.7980\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8002\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4916 - accuracy: 0.7948\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4637 - accuracy: 0.7990\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7981\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5405 - accuracy: 0.7583\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7971\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5012 - accuracy: 0.7865\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4667 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8005\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.7964\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4769 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5636 - accuracy: 0.7673\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4857 - accuracy: 0.7975\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7699\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7913\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4774 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5745 - accuracy: 0.7321\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.7974\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7891\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4692 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7984\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 7ms/step - loss: 0.4991 - accuracy: 0.7944\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4676 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8006\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5163 - accuracy: 0.7818\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4715 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7854\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4694 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7976\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5106 - accuracy: 0.7905\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.7977\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7992\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4883 - accuracy: 0.7960\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4649 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7998\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5173 - accuracy: 0.7695\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4671 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7993\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.4926 - accuracy: 0.7950\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4643 - accuracy: 0.7986\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4936 - accuracy: 0.7943\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4652 - accuracy: 0.7985\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7982\n",
      "Epoch 1/60\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.4926 - accuracy: 0.7915\n",
      "Epoch 2/60\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8004\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5945 - accuracy: 0.7170\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4843 - accuracy: 0.7961\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7982\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7757\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.7463\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.5168 - accuracy: 0.7843\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4937 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4663 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7985\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4956 - accuracy: 0.7956\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4653 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8006\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4874 - accuracy: 0.7970\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4638 - accuracy: 0.7989\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.7874\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4684 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7974\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5144 - accuracy: 0.7843\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4699 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7995\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5077 - accuracy: 0.7857\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7998\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5011 - accuracy: 0.7849\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8001\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5105 - accuracy: 0.7787\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4665 - accuracy: 0.7986\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7977\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5002 - accuracy: 0.7885\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4667 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7980\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.7902\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8009\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5690 - accuracy: 0.7411\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4856 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5368 - accuracy: 0.7827\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4795 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5188 - accuracy: 0.7921\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4747 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.5679 - accuracy: 0.7444\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.7981\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 6ms/step - loss: 0.5271 - accuracy: 0.7919\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.4805 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5156 - accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4718 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.7946\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.7977\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7998\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5049 - accuracy: 0.7930\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4687 - accuracy: 0.7984\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7969\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7944\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4689 - accuracy: 0.7982\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.5042 - accuracy: 0.7946\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4687 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7990\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.5062 - accuracy: 0.7880\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4669 - accuracy: 0.7976\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7990\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5218 - accuracy: 0.7816\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4690 - accuracy: 0.7979\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8001\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5195 - accuracy: 0.7747\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4676 - accuracy: 0.7985\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.5133 - accuracy: 0.7809\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4673 - accuracy: 0.7983\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 9ms/step - loss: 0.4956 - accuracy: 0.7909\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 9ms/step - loss: 0.4654 - accuracy: 0.7978\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7999\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7460 - accuracy: 0.6083\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5156 - accuracy: 0.7942\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7591\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.7962\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5356 - accuracy: 0.7907\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4878 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5521 - accuracy: 0.7807\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5810 - accuracy: 0.7412\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4963 - accuracy: 0.7969\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5529 - accuracy: 0.7616\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4838 - accuracy: 0.7969\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5752 - accuracy: 0.7289\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4830 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5176 - accuracy: 0.7916\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4743 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5246 - accuracy: 0.7807\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4788 - accuracy: 0.7977\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5374 - accuracy: 0.7797\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4800 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7992\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.5362 - accuracy: 0.7719\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4758 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7990\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5176 - accuracy: 0.7893\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4707 - accuracy: 0.7977\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7996\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.5232 - accuracy: 0.7858\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5083 - accuracy: 0.7884\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.4686 - accuracy: 0.7986\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7976\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5130 - accuracy: 0.7866\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4712 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.8003\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5554 - accuracy: 0.7881\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4929 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6207 - accuracy: 0.7095\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5124 - accuracy: 0.7969\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5526 - accuracy: 0.7937\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4877 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5331 - accuracy: 0.7967\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6173 - accuracy: 0.7054\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5077 - accuracy: 0.7973\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5513 - accuracy: 0.7578\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4821 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5352 - accuracy: 0.7830\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.4834 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5083 - accuracy: 0.7947\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4735 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7963\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5194 - accuracy: 0.7898\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4756 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5186 - accuracy: 0.7928\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4776 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7991\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.5430 - accuracy: 0.7715\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4804 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7983\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5054 - accuracy: 0.7933\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4686 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8004\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5064 - accuracy: 0.7956\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4692 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7965\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5268 - accuracy: 0.7789\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4737 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7968\n",
      "Epoch 1/45\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 0.5107 - accuracy: 0.7963\n",
      "Epoch 2/45\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.4723 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5874 - accuracy: 0.7413\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7973\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6888 - accuracy: 0.6498\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.7938\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7990\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5509 - accuracy: 0.7748\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5841 - accuracy: 0.7347\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4965 - accuracy: 0.7965\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.5518 - accuracy: 0.7736\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5257 - accuracy: 0.7825\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4755 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5338 - accuracy: 0.7797\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4785 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5325 - accuracy: 0.7798\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4774 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5510 - accuracy: 0.7574\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4831 - accuracy: 0.7977\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5482 - accuracy: 0.7658\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4833 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5093 - accuracy: 0.7908\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4699 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.5144 - accuracy: 0.7824\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4721 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7997\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5564 - accuracy: 0.7562\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.4789 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7969\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5246 - accuracy: 0.7758\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5637 - accuracy: 0.7397\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4781 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7994\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5603 - accuracy: 0.7692\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4964 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7983\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5928 - accuracy: 0.7424\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.7976\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.4724 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5653 - accuracy: 0.7626\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4950 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5381 - accuracy: 0.7880\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5986 - accuracy: 0.7115\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5030 - accuracy: 0.7973\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5132 - accuracy: 0.7953\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4744 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7985\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.5131 - accuracy: 0.7922\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.4767 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5290 - accuracy: 0.7757\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4789 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7963\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5293 - accuracy: 0.7814\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4787 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5545 - accuracy: 0.7559\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4846 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5247 - accuracy: 0.7798\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4755 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7984\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5163 - accuracy: 0.7884\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4734 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7991\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 0.5359 - accuracy: 0.7725\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4763 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7967\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5222 - accuracy: 0.7834\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4741 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7968\n",
      "Epoch 1/60\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5584 - accuracy: 0.7561\n",
      "Epoch 2/60\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.4804 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5776 - accuracy: 0.7496\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7975\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.7878 - accuracy: 0.5984\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7895\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7992\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6062 - accuracy: 0.7148\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7951\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.5940 - accuracy: 0.7098\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7979\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 0.6048 - accuracy: 0.7052\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7969\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5715 - accuracy: 0.7410\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4862 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5264 - accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4787 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7992\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5605 - accuracy: 0.7388\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4784 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5124 - accuracy: 0.7926\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4725 - accuracy: 0.7981\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7971\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5207 - accuracy: 0.7842\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.4780 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5435 - accuracy: 0.7676\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.4761 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7984\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5221 - accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4742 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7993\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.5266 - accuracy: 0.7797\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4716 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5162 - accuracy: 0.7856\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4724 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7973\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.5012 - accuracy: 0.7936\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.4690 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7998\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5858 - accuracy: 0.7447\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4910 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7240 - accuracy: 0.6185\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5175 - accuracy: 0.7924\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5865 - accuracy: 0.7648\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5022 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.5882 - accuracy: 0.7354\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.4966 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5808 - accuracy: 0.7393\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.5019 - accuracy: 0.7970\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5227 - accuracy: 0.7889\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.4775 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.7453\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4879 - accuracy: 0.7974\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5449 - accuracy: 0.7734\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4829 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7963\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.5091 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4725 - accuracy: 0.7982\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.5632 - accuracy: 0.7495\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.4860 - accuracy: 0.7971\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5111 - accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4718 - accuracy: 0.7978\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7983\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5098 - accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4725 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.5072 - accuracy: 0.7940\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4712 - accuracy: 0.7983\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7968\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 0.4962 - accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.4672 - accuracy: 0.7984\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7978\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.5186 - accuracy: 0.7811\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.4729 - accuracy: 0.7976\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7991\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 3s 3ms/step - loss: 0.4733 - accuracy: 0.7949\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 3ms/step - loss: 0.4573 - accuracy: 0.8001\n",
      "Best params: {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
      "Best average accuracy: 0.800796377658844\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# KerasClassifier을 위한 build_fn 정의 (build_model)\n",
    "# 신경망 model 생성\n",
    "def build_model(num_layers, num_nodes, loss):\n",
    "    # Define and compile the model\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(num_nodes, input_dim=86, activation='relu'))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(num_nodes, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='Adam', loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# KFold validation 사용\n",
    "# k: n_splits=5\n",
    "kfold = KFold(random_state=30,\n",
    "           n_splits=5,\n",
    "           shuffle=True\n",
    "          )\n",
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model)\n",
    "\n",
    "# 최적 hyperparameter을 찾기위한 gridsearchCV를 위한 parameter\n",
    "parameters = {\n",
    "    'batch_size': [1000,5000,10000],\n",
    "    'epochs': [45,60,100],\n",
    "    'num_layers': [2, 3],\n",
    "    'num_nodes': [10, 25, 40],\n",
    "    'loss':[\"categorical_crossentropy\"]\n",
    "    }\n",
    "# GridSearchCV 생성\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parameters,\n",
    "                           cv = kfold)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "# GridSearchCV fit 시작\n",
    "grid_search.fit(x_train, y_train, callbacks=[early_stopping])\n",
    "# 최적의 param\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "# 최적의 param일 경우 최적의 accuracy\n",
    "print(f\"Best average accuracy: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search를 수행했을 경우의 각각의 결과\n",
    "result = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 위의 모델을 생성한 결과를 바탕으로 hyperparameter를 설정한 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 모델(without EarlyStopping)\n",
    "- avg accuracy: 0.8004517912864685\n",
    "- avg F1-score: 0.8004525303840637\n",
    "- avg recall: 0.8004526019096374\n",
    "- avg precision: 0.8004526019096374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "   print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4726 - accuracy: 0.7955 - f1_score: 0.7956 - recall: 0.7956 - precision: 0.7956\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4583 - accuracy: 0.7996 - f1_score: 0.7996 - recall: 0.7996 - precision: 0.7996\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4562 - accuracy: 0.8002 - f1_score: 0.8002 - recall: 0.8002 - precision: 0.8002\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4549 - accuracy: 0.8008 - f1_score: 0.8007 - recall: 0.8007 - precision: 0.8007\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4540 - accuracy: 0.8008 - f1_score: 0.8008 - recall: 0.8008 - precision: 0.8008\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4534 - accuracy: 0.8013 - f1_score: 0.8012 - recall: 0.8012 - precision: 0.8012\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4529 - accuracy: 0.8011 - f1_score: 0.8010 - recall: 0.8010 - precision: 0.8010\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.8013 - f1_score: 0.8014 - recall: 0.8014 - precision: 0.8014\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4521 - accuracy: 0.8015 - f1_score: 0.8014 - recall: 0.8014 - precision: 0.8014\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4517 - accuracy: 0.8015 - f1_score: 0.8015 - recall: 0.8015 - precision: 0.8015\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4513 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4511 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4508 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4507 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4505 - accuracy: 0.8023 - f1_score: 0.8023 - recall: 0.8023 - precision: 0.8023\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4504 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4501 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4499 - accuracy: 0.8022 - f1_score: 0.8023 - recall: 0.8023 - precision: 0.8023\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4499 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.8022 - f1_score: 0.8022 - recall: 0.8022 - precision: 0.8022\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4496 - accuracy: 0.8023 - f1_score: 0.8023 - recall: 0.8023 - precision: 0.8023\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4493 - accuracy: 0.8024 - f1_score: 0.8024 - recall: 0.8024 - precision: 0.8024\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4494 - accuracy: 0.8025 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4492 - accuracy: 0.8023 - f1_score: 0.8023 - recall: 0.8023 - precision: 0.8023\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4490 - accuracy: 0.8024 - f1_score: 0.8024 - recall: 0.8024 - precision: 0.8024\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4489 - accuracy: 0.8025 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4488 - accuracy: 0.8024 - f1_score: 0.8024 - recall: 0.8024 - precision: 0.8024\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4488 - accuracy: 0.8024 - f1_score: 0.8024 - recall: 0.8024 - precision: 0.8024\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4487 - accuracy: 0.8026 - f1_score: 0.8025 - recall: 0.8025 - precision: 0.8025\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4486 - accuracy: 0.8026 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4486 - accuracy: 0.8026 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4485 - accuracy: 0.8028 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4484 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4482 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4482 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4482 - accuracy: 0.8026 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4481 - accuracy: 0.8027 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4481 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4479 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4479 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4478 - accuracy: 0.8031 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4477 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4477 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4479 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4478 - accuracy: 0.8028 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4476 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4476 - accuracy: 0.8030 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4474 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4474 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4474 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8031 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8032 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 62/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4469 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4470 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4469 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4470 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4532 - accuracy: 0.8015 - f1_score: 0.8015 - recall: 0.8015 - precision: 0.8015\n",
      "===================================\n",
      "Validation accuracy: 0.8014955520629883\n",
      "Validation F1-score: 0.801500141620636\n",
      "Validation recall: 0.8015002608299255\n",
      "Validation precision: 0.8015002608299255\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4482 - accuracy: 0.8025 - f1_score: 0.8025 - recall: 0.8025 - precision: 0.8025\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4480 - accuracy: 0.8027 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4478 - accuracy: 0.8027 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4477 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4477 - accuracy: 0.8027 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4474 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4474 - accuracy: 0.8027 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8031 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8030 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4472 - accuracy: 0.8028 - f1_score: 0.8028 - recall: 0.8028 - precision: 0.8028\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4470 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4470 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8029 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4469 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8029 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4468 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8030 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8029 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8033 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8031 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8029 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8030 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8028 - f1_score: 0.8027 - recall: 0.8027 - precision: 0.8027\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 62/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8034 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8030 - f1_score: 0.8029 - recall: 0.8029 - precision: 0.8029\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4507 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "===================================\n",
      "Validation accuracy: 0.8035555481910706\n",
      "Validation F1-score: 0.8035518527030945\n",
      "Validation recall: 0.8035519123077393\n",
      "Validation precision: 0.8035519123077393\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8036 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8036 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8035 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8036 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8041 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8039 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8042 - f1_score: 0.8042 - recall: 0.8042 - precision: 0.8042\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8040 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 62/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8036 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8039 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8041 - f1_score: 0.8041 - recall: 0.8041 - precision: 0.8041\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8041 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8041 - recall: 0.8041 - precision: 0.8041\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4445 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4517 - accuracy: 0.8014 - f1_score: 0.8014 - recall: 0.8014 - precision: 0.8014\n",
      "===================================\n",
      "Validation accuracy: 0.8013519644737244\n",
      "Validation F1-score: 0.8013727068901062\n",
      "Validation recall: 0.8013728260993958\n",
      "Validation precision: 0.8013728260993958\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8034 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8036 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8037 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8041 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 62/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8041 - f1_score: 0.8041 - recall: 0.8041 - precision: 0.8041\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8039 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8041 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4445 - accuracy: 0.8040 - f1_score: 0.8040 - recall: 0.8040 - precision: 0.8040\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4444 - accuracy: 0.8042 - f1_score: 0.8042 - recall: 0.8042 - precision: 0.8042\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4444 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4445 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4445 - accuracy: 0.8039 - f1_score: 0.8039 - recall: 0.8039 - precision: 0.8039\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4495 - accuracy: 0.8021 - f1_score: 0.8021 - recall: 0.8021 - precision: 0.8021\n",
      "===================================\n",
      "Validation accuracy: 0.8020588755607605\n",
      "Validation F1-score: 0.802055299282074\n",
      "Validation recall: 0.8020554184913635\n",
      "Validation precision: 0.8020554184913635\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4464 - accuracy: 0.8030 - f1_score: 0.8030 - recall: 0.8030 - precision: 0.8030\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4461 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.8034 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4459 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8033 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8034 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4457 - accuracy: 0.8031 - f1_score: 0.8031 - recall: 0.8031 - precision: 0.8031\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8032 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8033 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8034 - f1_score: 0.8033 - recall: 0.8033 - precision: 0.8033\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8033 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4454 - accuracy: 0.8032 - f1_score: 0.8032 - recall: 0.8032 - precision: 0.8032\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8034 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8034 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8035 - f1_score: 0.8034 - recall: 0.8034 - precision: 0.8034\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8038 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 62/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4451 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4450 - accuracy: 0.8037 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8034 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8036 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8036 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8037 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.8036 - f1_score: 0.8036 - recall: 0.8036 - precision: 0.8036\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.8038 - f1_score: 0.8038 - recall: 0.8038 - precision: 0.8038\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.8035 - f1_score: 0.8035 - recall: 0.8035 - precision: 0.8035\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.8037 - f1_score: 0.8037 - recall: 0.8037 - precision: 0.8037\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4477 - accuracy: 0.8041 - f1_score: 0.8041 - recall: 0.8041 - precision: 0.8041\n",
      "===================================\n",
      "Validation accuracy: 0.804063618183136\n",
      "Validation F1-score: 0.8040518164634705\n",
      "Validation recall: 0.80405193567276\n",
      "Validation precision: 0.80405193567276\n",
      "###################################\n",
      "avg Validation accuracy: 0.8025051116943359\n",
      "avg Validation F1-score: 0.8025063633918762\n",
      "avg Validation recall: 0.8025064706802368\n",
      "avg Validation precision: 0.8025064706802368\n"
     ]
    }
   ],
   "source": [
    "# # 최고의 파라미터 : {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=86, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss=best_params['loss'], optimizer='Adam', metrics=[\"accuracy\", f1_score, recall, precision])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1)\n",
    "\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc, valid_f1, valid_recall, valid_precision = model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    valid_f1s.append(valid_f1)\n",
    "    valid_recalls.append(valid_recall)\n",
    "    valid_precisions.append(valid_precision)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "    print(\"Validation F1-score:\", valid_f1)\n",
    "    print(\"Validation recall:\", valid_recall)\n",
    "    print(\"Validation precision:\", valid_precision)\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dnn_models/non_log_transformed/pca1_feature86/without_earlystopping_0421.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 model(with EarlyStopping)\n",
    "### earlystopping: min_delta was 0.001\n",
    "- avg accuracy: 0.7999342799186706\n",
    "- avg F1-score: 0.7999348163604736\n",
    "- avg recall: 0.7999348998069763\n",
    "- avg precision: 0.7999348998069763\n",
    "\n",
    "### earlystopping: min_delta was 0.0001\n",
    "- avg accuracy: 0.80015869140625\n",
    "- avg F1-score: 0.8001592040061951\n",
    "- avg recall: 0.8001593112945556\n",
    "- avg precision: 0.8001593112945556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4687 - accuracy: 0.7984 - f1_score: 0.7984 - recall: 0.7984 - precision: 0.7984\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4575 - accuracy: 0.7998 - f1_score: 0.7999 - recall: 0.7999 - precision: 0.7999\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4541 - accuracy: 0.8005 - f1_score: 0.8006 - recall: 0.8006 - precision: 0.8006\n",
      "===================================\n",
      "Validation accuracy: 0.8005456328392029\n",
      "Validation F1-score: 0.8005503416061401\n",
      "Validation recall: 0.8005504608154297\n",
      "Validation precision: 0.8005504608154297\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4555 - accuracy: 0.8004 - f1_score: 0.8004 - recall: 0.8004 - precision: 0.8004\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4542 - accuracy: 0.8008 - f1_score: 0.8008 - recall: 0.8008 - precision: 0.8008\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4532 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "===================================\n",
      "Validation accuracy: 0.8019374012947083\n",
      "Validation F1-score: 0.801925778388977\n",
      "Validation recall: 0.8019258975982666\n",
      "Validation precision: 0.8019258975982666\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4531 - accuracy: 0.8016 - f1_score: 0.8016 - recall: 0.8016 - precision: 0.8016\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4524 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4542 - accuracy: 0.8006 - f1_score: 0.8006 - recall: 0.8006 - precision: 0.8006\n",
      "===================================\n",
      "Validation accuracy: 0.8005732893943787\n",
      "Validation F1-score: 0.8005940914154053\n",
      "Validation recall: 0.8005942106246948\n",
      "Validation precision: 0.8005942106246948\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4521 - accuracy: 0.8007 - f1_score: 0.8007 - recall: 0.8007 - precision: 0.8007\n",
      "===================================\n",
      "Validation accuracy: 0.8007334470748901\n",
      "Validation F1-score: 0.8007299900054932\n",
      "Validation recall: 0.8007301092147827\n",
      "Validation precision: 0.8007301092147827\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4524 - accuracy: 0.8014 - f1_score: 0.8014 - recall: 0.8014 - precision: 0.8014\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 0.4519 - accuracy: 0.8018 - f1_score: 0.8018 - recall: 0.8018 - precision: 0.8018\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4499 - accuracy: 0.8026 - f1_score: 0.8026 - recall: 0.8026 - precision: 0.8026\n",
      "===================================\n",
      "Validation accuracy: 0.8026387691497803\n",
      "Validation F1-score: 0.8026190400123596\n",
      "Validation recall: 0.8026190996170044\n",
      "Validation precision: 0.8026190996170044\n",
      "###################################\n",
      "avg Validation accuracy: 0.8012857079505921\n",
      "avg Validation F1-score: 0.801283848285675\n",
      "avg Validation recall: 0.8012839555740356\n",
      "avg Validation precision: 0.8012839555740356\n"
     ]
    }
   ],
   "source": [
    "# # 최고의 파라미터 : {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=86, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss=best_params['loss'], optimizer='Adam', metrics=[\"accuracy\", f1_score, recall, precision])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.001)\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc, valid_f1, valid_recall, valid_precision = model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    valid_f1s.append(valid_f1)\n",
    "    valid_recalls.append(valid_recall)\n",
    "    valid_precisions.append(valid_precision)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "    print(\"Validation F1-score:\", valid_f1)\n",
    "    print(\"Validation recall:\", valid_recall)\n",
    "    print(\"Validation precision:\", valid_precision)\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n",
    "model.save('dnn_models/non_log_transformed/pca1_feature86/with_earlystopping_001_0421.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4725 - accuracy: 0.7965 - f1_score: 0.7965 - recall: 0.7965 - precision: 0.7965\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.7998 - f1_score: 0.7998 - recall: 0.7998 - precision: 0.7998\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4563 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "===================================\n",
      "Validation accuracy: 0.8016557097434998\n",
      "Validation F1-score: 0.8016602993011475\n",
      "Validation recall: 0.801660418510437\n",
      "Validation precision: 0.801660418510437\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4560 - accuracy: 0.8004 - f1_score: 0.8004 - recall: 0.8004 - precision: 0.8004\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 3ms/step - loss: 0.4545 - accuracy: 0.8009 - f1_score: 0.8009 - recall: 0.8009 - precision: 0.8009\n",
      "5659/5659 [==============================] - 7s 1ms/step - loss: 0.4535 - accuracy: 0.8020 - f1_score: 0.8020 - recall: 0.8020 - precision: 0.8020\n",
      "===================================\n",
      "Validation accuracy: 0.8019981384277344\n",
      "Validation F1-score: 0.801986575126648\n",
      "Validation recall: 0.8019866347312927\n",
      "Validation precision: 0.8019866347312927\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.8015 - f1_score: 0.8015 - recall: 0.8015 - precision: 0.8015\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4533 - accuracy: 0.8011 - f1_score: 0.8011 - recall: 0.8011 - precision: 0.8011\n",
      "===================================\n",
      "Validation accuracy: 0.8010979294776917\n",
      "Validation F1-score: 0.801118791103363\n",
      "Validation recall: 0.801118791103363\n",
      "Validation precision: 0.801118791103363\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.8016 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4521 - accuracy: 0.8019 - f1_score: 0.8019 - recall: 0.8019 - precision: 0.8019\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4517 - accuracy: 0.8013 - f1_score: 0.8013 - recall: 0.8013 - precision: 0.8013\n",
      "===================================\n",
      "Validation accuracy: 0.8013133406639099\n",
      "Validation F1-score: 0.8013017773628235\n",
      "Validation recall: 0.801301896572113\n",
      "Validation precision: 0.801301896572113\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.8018 - f1_score: 0.8018 - recall: 0.8018 - precision: 0.8018\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 4ms/step - loss: 0.4517 - accuracy: 0.8017 - f1_score: 0.8017 - recall: 0.8017 - precision: 0.8017\n",
      "5659/5659 [==============================] - 6s 1ms/step - loss: 0.4502 - accuracy: 0.8021 - f1_score: 0.8021 - recall: 0.8021 - precision: 0.8021\n",
      "===================================\n",
      "Validation accuracy: 0.8020754456520081\n",
      "Validation F1-score: 0.8020557761192322\n",
      "Validation recall: 0.802055835723877\n",
      "Validation precision: 0.802055835723877\n",
      "###################################\n",
      "avg Validation accuracy: 0.8016281127929688\n",
      "avg Validation F1-score: 0.8016246438026429\n",
      "avg Validation recall: 0.8016247153282166\n",
      "avg Validation precision: 0.8016247153282166\n"
     ]
    }
   ],
   "source": [
    "# # 최고의 파라미터 : {'batch_size': 1000, 'epochs': 100, 'loss': 'categorical_crossentropy', 'num_layers': 2, 'num_nodes': 40}\n",
    "valid_accs, valid_f1s, valid_recalls, valid_precisions = [], [], [], []\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 신경망층 설계\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(best_params['num_nodes'], input_dim=86, activation='relu'))\n",
    "for _ in range(best_params['num_layers']):\n",
    "    model.add(Dense(best_params['num_nodes'], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 모델 컴파일\n",
    "model.compile(loss=best_params['loss'], optimizer='Adam', metrics=[\"accuracy\", f1_score, recall, precision])\n",
    "# KFoldvalidation 사용함(k=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "early_stopping = EarlyStopping(monitor='loss',min_delta=0.0001)\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_fold, Y_train_fold, \n",
    "              batch_size=best_params['batch_size'], \n",
    "              epochs=best_params['epochs'], \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    # 모델 validation\n",
    "    valid_loss, valid_acc, valid_f1, valid_recall, valid_precision = model.evaluate(X_val_fold, Y_val_fold)\n",
    "    valid_accs.append(valid_acc)\n",
    "    valid_f1s.append(valid_f1)\n",
    "    valid_recalls.append(valid_recall)\n",
    "    valid_precisions.append(valid_precision)\n",
    "    print(\"===================================\")\n",
    "    print(\"Validation accuracy:\", valid_acc)\n",
    "    print(\"Validation F1-score:\", valid_f1)\n",
    "    print(\"Validation recall:\", valid_recall)\n",
    "    print(\"Validation precision:\", valid_precision)\n",
    "print(\"###################################\")\n",
    "print(\"avg Validation accuracy:\", np.mean(valid_accs))\n",
    "print(\"avg Validation F1-score:\", np.mean(valid_f1s))\n",
    "print(\"avg Validation recall:\", np.mean(valid_recalls))\n",
    "print(\"avg Validation precision:\", np.mean(valid_precisions))\n",
    "model.save('dnn_models/non_log_transformed/pca1_feature86/with_earlystopping_0001_0421.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
